## NEXT STEPS




## Backlog (что хотелось бы сделать потом).
- [ ] В ПЕРВУЮ ОЧЕРЕДЬ, если возобновлю работу: убрать sys.path.append

- [ ] ОПТИМИЗАЦИЯ: реализовать _has_neighbour_word() с кэшированием, чтобы для одного и того же id не проводить заново проверки (непонятно, сколько сэкономим, потому что будет экономия только left neighbours для id, который даёт несколько слов, начинающихся одинаково, типа рыб рыба рыбак рыбаки)
- [ ] ОПТИМИЗАЦИЯ: ленивая генерация n-грамм из первых букв
- [ ] ОПТИМИЗАЦИЯ: разобраться, какой адекватный размер для добавления букв до max_word_size, чтобы не упустить интересное, но и чтобы не делать много лишних вычислений
- [ ] Тестирование: нужно больше тестов, на ключевые узлы

- [ ] КОРПУС: поэтический https://raw.githubusercontent.com/IlyaGusev/PoetryCorpus/refs/heads/master/datasets/corpus/all.xml (пустить через пайплайн research.ipynb)

- [ ] Добавить проверку двух соседних слов (оба слева, оба справа, одно слева, одно справа)


## Архитектурные заметки — идеи для рефакторинга.



## DONE

### 0. БАЗОВАЯ СТРУКТУРА
- [x] 1. Создана проектная папка со структурой, гит, репо в гитхабе
- [x] 2. Реализовал первичный пайплайн обработки одного текста и поиска акростихов по словарю

### I. НЕМНОЖКО ПОРЯДКА

- [x] 1. Почистить код:
  - [x] Аннотации типов во всех методах
  - [x] Хорошие Docstring для всех API методов (пока только scan_text), схема из PEP 257 --
    - краткое описание, через строку Аргументы: с отступом, через строку Возвращает: с отступом
    - для приватных методов -- по необходимости, без детализации, для __init__ тоже
- [x] 2. Реализовать load_dictionary, найти хороший словарь (в salvage-материалах мб слишком большой)
- [x] 3. Опционально: единицу результата Candidate вынести в датакласс
- [x] 4. Минимальные тесты


### II. РЕАЛИЗОВЫВАЕМ ПОИСК РЕАЛЬНЫХ КАНДИДАТОВ

- [x] 0. Реализовать поиск кандидатов во всех текстах заданной директории и сведение результатов в единой таблице
- [x] 1. Реализовать фильтрацию найденных кандидатов через достройку до полного слова
- [x] 2. bug-fix: сейчас в найденные слова попадают слова, набранные р а з р я д к о й, нужно сделать проверку на такие случаи
- [x] 3. Сделать контекст в результатах таким, чтобы туда попадали все слова, составляющие сочетение
- [x] 4. Сделать проверку через достройку соседних слов 
- [x] 5. КЛЮЧЕВОЙ ВОПРОС: не излишне ли делать несколько n_gram??? типа, начинаем с меньшей и дальше мы же достраиваем до слова
- [x] 6. Вынести все настраиваемые параметры в аргументы (в т.ч. проверку соседей и длину соседей)
- [x] 7. Добавить параметр -- пользовательский словарь, чтобы искать одно слово по всему корпусу в акростихах (чтобы можно было забавные слова искать или своё имя)


### III. CLI, форма вывода результатов
- [X] Добавить отчёт о сканировании директории от batch_scanner
  - проверена директория X, параметры сканирования, число файлов, найденных кандидатов
- [X] Сохранять таблицу и отчёт о сканировании в директорию с результатми (проверять её наличие), уникальный префикс для названия файлов, чтобы разные прогоны не сохранялись в один файл
- [X] CLI интерфейс со всеми нужными параметрами в качестве аргументов

### IV. ПУБЛИКАЦИЯ
- [X] оформить readme
- [X] ноутбук с запуском scan.py и импортом результатов
- [X] requirements.txt

### V. Финальное исследование
- [X] Сделать блокнот для запуска в коллабе (загрузка большого словаря, загрузка корпусов и прогон)
- [X] Загрузка и обработка словаря (В словаре надо удалить все знаки, которые не могут быть первыми! (причём, возможно надо или удалить -- мягкий, твёрдый, например -- или заменить -- ы на и, э на е и проч, причём, возможно, оставив и с ы/э на всякий случай варианты) TODO: добавить это в ограничения в readme)